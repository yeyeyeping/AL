{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from matplotlib.pyplot import imshow\n",
    "import numpy as np\n",
    "import torch\n",
    "from scipy.ndimage import zoom\n",
    "from scipy import ndimage\n",
    "from model.MGUnet import MGUNet\n",
    "from util import read_yml\n",
    "from util.reader import reader\n",
    "from scipy import ndimage\n",
    "from albumentations import functional\n",
    "\n",
    "\n",
    "cfg_path, img_folder, ckpath, out_dir, input_size = [\"/yeping/new/AL-ACDC/EXP/ISIC_exp/SSL/0.03/Baseline/config.yml\", \"/yeping/new/AL-ACDC/data/ISIC/val/images/\" ,\"/yeping/new/AL-ACDC/EXP/ISIC_exp/SSL/0.03/Baseline/checkpoint/c0_best0.8198.pt\", \"/yeping/new/AL-ACDC/EXP/ISIC_exp/SSL/0.03/Baseline/inference/\" ,\"416\"]\n",
    "input_size = int(input_size)\n",
    "assert os.path.exists(img_folder) and os.path.exists(ckpath)\n",
    "\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "cfg_path = read_yml(cfg_path)\n",
    "model = MGUNet(cfg_path[\"Network\"]).to(device)\n",
    "\n",
    "model.load_state_dict(torch.load(ckpath, map_location=device)[\"model_state_dict\"])\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_largest_k_components(image, k=1):\n",
    "    \"\"\"\n",
    "    Get the largest K components from 2D or 3D binary image.\n",
    "\n",
    "    :param image: The input ND array for binary segmentation.\n",
    "    :param k: (int) The value of k.\n",
    "\n",
    "    :return: An output array with only the largest K components of the input.\n",
    "    \"\"\"\n",
    "    dim = len(image.shape)\n",
    "    if (image.sum() == 0):\n",
    "        print('the largest component is null')\n",
    "        return image\n",
    "    if (dim < 2 or dim > 3):\n",
    "        raise ValueError(\"the dimension number should be 2 or 3\")\n",
    "    s = ndimage.generate_binary_structure(dim, 1)\n",
    "    labeled_array, numpatches = ndimage.label(image, s)\n",
    "    sizes = ndimage.sum(image, labeled_array, range(1, numpatches + 1))\n",
    "    sizes_sort = sorted(sizes, reverse=True)\n",
    "    kmin = min(k, numpatches)\n",
    "    output = np.zeros_like(image)\n",
    "    for i in range(kmin):\n",
    "        labeli = np.where(sizes == sizes_sort[i])[0] + 1\n",
    "        output = output + np.asarray(labeled_array == labeli, np.uint8)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = \"/yeping/new/AL-ACDC/data/ISIC/test/images/ISIC_0000001.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_npy = reader(g)().read_image(g)\n",
    "mean=(0.485, 0.456, 0.406)\n",
    "std=(0.229, 0.224, 0.225)\n",
    "img_npy = functional.normalize(img_npy,mean,std)\n",
    "img_npy = np.ascontiguousarray(img_npy.transpose(2, 0, 1))[None]\n",
    "\n",
    "*_, h, w = img_npy.shape\n",
    "\n",
    "zoomed_img = zoom(img_npy, (1, 1, input_size / h, input_size / w), order=1,\n",
    "                    mode='nearest')\n",
    "zoomed_img = torch.from_numpy(zoomed_img).cuda()\n",
    "output, _, _ = model(zoomed_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(zoomed_img[0].permute(1,2,0).detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(output[0].argmax(1).detach().cpu()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_pred_mask = output[0].argmax(axis=1)[0].detach().cpu().numpy()\n",
    "pred_volume = zoom(batch_pred_mask, (h / input_size, w / input_size), order=0,\n",
    "                    mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(pred_volume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_pred_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = get_largest_k_components(batch_pred_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "s = ndimage.generate_binary_structure(2,1)\n",
    "v = ndimage.binary_opening(v,s)\n",
    "v = ndimage.binary_closing(v,s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(v\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.load(\"/yeping/new/AL-ACDC/data/ISIC/test/mask/ISIC_0000001.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = zoom(mask,(416/1024,416/1024),order=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import numpy as np\n",
    "from scipy.ndimage import zoom\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dir = \"/yeping/new/AL-ACDC/data/ISIC/test_size416\"\n",
    "source_dir = \"/yeping/new/AL-ACDC/data/ISIC/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for  name in os.listdir(osp.join(source_dir, \"mask\")):\n",
    "    img_path = osp.join(osp.join(source_dir, \"images\",name))\n",
    "    mask_path = osp.join(osp.join(source_dir, \"mask\",name))\n",
    "    i, g = np.load(img_path),np.load(mask_path)\n",
    "    g = zoom(g, (416 / i.shape[0], 416 / i.shape[1]), order=0,\n",
    "                          mode='nearest')\n",
    "    i = zoom(i, (416 / i.shape[0], 416 / i.shape[1],1), order=1,\n",
    "                          mode='nearest')\n",
    "    target_img_path = osp.join(osp.join(target_dir, \"images\",name))\n",
    "    target_mask_path = osp.join(osp.join(target_dir, \"mask\",name))\n",
    "    np.save(target_img_path, i)\n",
    "    np.save(target_mask_path, g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import  imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i,g = np.load(\"/yeping/new/AL-ACDC/data/ISIC/test_size416/images/ISIC_0000001.npy\"),np.load(\"/yeping/new/AL-ACDC/data/ISIC/test_size416/mask/ISIC_0000001.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import  pad,interpolate\n",
    "import torch\n",
    "import numpy as np\n",
    "from matplotlib.pyplot import imshow\n",
    "from torchvision.utils import make_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_size = 16\n",
    "mask_ratio = 0.1\n",
    "img = np.load('/home/yeep/project/py/deeplearning/AL-ACDC/data/ISIC/test/images/ISIC_0000017.npy')\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = torch.from_numpy(np.ascontiguousarray(img.transpose(2,0,1))).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = img.permute(1,2,0)\n",
    "h,w = img.shape[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patched_data = torch.stack([p for f in torch.chunk(img, patch_size)\n",
    "                   for p in torch.chunk(f, patch_size, dim=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_num,c = patched_data.shape[0],patched_data.shape[-1]\n",
    "num_patch_pixel = patch_size*patch_size\n",
    "selected_idx = torch.randperm(patch_num)[:int(patch_num*mask_ratio)]\n",
    "selected_patch = patched_data[selected_idx]\n",
    "shuffled_patch = [p.view(num_patch_pixel,c)[torch.randperm(num_patch_pixel,device=device)].view(patch_size,patch_size,c)for p in selected_patch]\n",
    "patched_data[selected_idx] = torch.stack(shuffled_patch)\n",
    "shuffled_img = make_grid(patched_data.permute(0,3,1,2),nrow=h//patch_size,padding=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(shuffled_img.permute(1,2,0).cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.load('/home/yeep/project/py/deeplearning/AL-ACDC/data/ISIC/test/images/ISIC_0000017.npy')\n",
    "img = torch.from_numpy(img).permute(2,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import  pad,interpolate\n",
    "import torch\n",
    "import numpy as np\n",
    "from matplotlib.pyplot import imshow\n",
    "from torchvision.utils import make_grid\n",
    "def tensor_shuffle(input):\n",
    "    return input[torch.randperm(len(input),device=input.device)]\n",
    "\n",
    "def local_shuffle(img: torch.Tensor, mask_ratio: float = 0.5, patch_size: int = 16, enable_patch_exchange: bool = False):\n",
    "    '''\n",
    "     img: c h w\n",
    "     return: shuffled_img:torch.Tensor(c h w )\n",
    "    '''\n",
    "    img = img.to(device)\n",
    "    img = img.permute(1, 2, 0)\n",
    "    h, w = img.shape[:2]\n",
    "\n",
    "    assert h % patch_size == 0 and w % patch_size == 0, f\"img : {h,w} patch_size: {patch_size}\"\n",
    "    # 切割img成hxw/patch_size/patch_size个patch size x patch size的小块\n",
    "    patched_data = torch.stack([p for f in torch.chunk(img, h//patch_size)\n",
    "                                for p in torch.chunk(f, w//patch_size, dim=1)])\n",
    "    patch_num, c = patched_data.shape[0], patched_data.shape[-1]\n",
    "    num_patch_pixel = patch_size*patch_size\n",
    "\n",
    "    selected_idx = torch.randperm(patch_num)[:int(patch_num*mask_ratio)]\n",
    "    if enable_patch_exchange:\n",
    "        patched_data = tensor_shuffle(patched_data)\n",
    "    selected_patch = patched_data[selected_idx]\n",
    "    shuffled_patch = [tensor_shuffle(p.view(num_patch_pixel, c)).view(patch_size, patch_size, c) for p in selected_patch]\n",
    "    patched_data[selected_idx] = torch.stack(shuffled_patch)\n",
    "    shuffled_img = make_grid(patched_data.permute(\n",
    "        0, 3, 1, 2), nrow=w//patch_size, padding=0)\n",
    "    return shuffled_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import SimpleITK as sitk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = sitk.GetArrayFromImage(sitk.ReadImage(\"/home/yeep/project/py/deeplearning/AL-ACDC/data/ACDCprecessed/test/patient084_frame01.nii.gz\"))\n",
    "img = torch.from_numpy(img[0][None]).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = local_shuffle(img,patch_size=16,mask_ratio=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "a = fig.add_subplot(1,2,1)\n",
    "a.imshow(img.permute(1,2,0).cpu(),cmap=\"gray\")\n",
    "a2 = fig.add_subplot(1,2,2)\n",
    "a2.imshow(out.cpu().permute(1,2,0),cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.load('/home/yeep/project/py/deeplearning/AL-ACDC/data/ISIC/test/images/ISIC_0000017.npy')\n",
    "img = torch.from_numpy(img).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img = img.permute(2,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o = local_shuffle(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "imshow(o.permute(1,2,0).cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import SimpleITK as sitk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset.ACDCDataset import ISICDataset\n",
    "import  albumentations as A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = A.Compose([\n",
    "    A.HorizontalFlip(),\n",
    "    A.VerticalFlip(),\n",
    "    A.RandomRotate90(p=0.2),\n",
    "    A.ColorJitter(brightness=32 / 255, saturation=0.5),\n",
    "    A.Normalize(max_pixel_value=1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = ISICDataset(\"/home/yeep/project/py/deeplearning/AL-ACDC/data/Cadis/Cadispreprocessed/train\",transform=train_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ii,i in enumerate(d):\n",
    "    img,lab = i\n",
    "    if list(img.shape)!=[3, 180, 320]:\n",
    "        print(ii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import kmeans_plusplus\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inter_class_var(img:torch.Tensor):\n",
    "    '''img: BxCxHxW'''\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.functional import pairwise_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_label = pred > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  class_var_score(pred, image):\n",
    "    sample_score = []\n",
    "    for p, i in zip(pred, image):\n",
    "        label = p > 0.5\n",
    "\n",
    "        class_center = []\n",
    "        class_var = []\n",
    "        for l in label:\n",
    "            class_pix = i[:, l]\n",
    "            class_center.append(class_pix.mean(1))\n",
    "\n",
    "            var = torch.std(class_pix, dim=1).mean()\n",
    "            class_var.append(var)\n",
    "\n",
    "        # 类间散度：中心点之间的距离\n",
    "        class_center = torch.stack(class_center)\n",
    "        center = class_center.mean(0)\n",
    "        between_class = pairwise_distance(class_center, center[None]).sum()\n",
    "        # 类内方差\n",
    "        inner_var = torch.mean(torch.as_tensor(class_var))\n",
    "        inner_var = inner_var*0.999 + 1e-5\n",
    "        score = between_class / inner_var\n",
    "        sample_score.append(score)\n",
    "    return sample_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = torch.randn(16,2,96,96).softmax(1)\n",
    "image = torch.randint(0,255,(16,3,96,96),dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_var_score(pred, image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_label = pred > 0.5\n",
    "foreground = (pred[:,:,None] * image[:,None])\n",
    "background = (pred[:,:,None].logical_not() * image[:,None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_center = foreground.mean(dim=[-1,-2])\n",
    "center = class_center.mean(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred[:,torch.randn(4,96,96)>0.5].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from skimage.io import imread\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Path(\"/home/yeep/project/py/deeplearning/AL-ACDC/data/Cadis/cadis/split2023/data\")\n",
    "mask_folder = list(data.rglob(\"mask\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for folder in mask_folder:\n",
    "    for png in folder.glob(\"*.png\"):\n",
    "        mask = imread(str(png),as_gray=True)\n",
    "        counts = Counter(mask.flatten())        \n",
    "        for k,v in counts.items():\n",
    "            m[k] = m.get(k,0) + v\n",
    "            p[k] = p.get(k,0) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict(sorted(m.items(),key=lambda x : x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_label(path_list):\n",
    "    m = {}\n",
    "    p = {}\n",
    "    for png in path_list:\n",
    "        mask = imread(str(png),as_gray=True)\n",
    "        counts = Counter(mask.flatten())        \n",
    "        for k,v in counts.items():\n",
    "            m[k] = m.get(k,0) + v\n",
    "            p[k] = p.get(k,0) + 1\n",
    "    return  dict(sorted(m.items(),key=lambda x : x[0])), dict(sorted(p.items(),key=lambda x : x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Path(\"/home/yeep/project/py/deeplearning/AL-ACDC/data/Cadis/cadis/split2023/data\")\n",
    "mask_folder = list(data.rglob(\"mask\"))\n",
    "mask_path = [l  for p in mask_folder for l in p.iterdir()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m, p = count_label(mask_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m, p = count_label(Path(\"/home/yeep/project/py/deeplearning/AL-ACDC/data/Cadis/cadis/split2023/data/test/mask\").iterdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m,p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m, p = count_label(Path(\"/home/yeep/project/py/deeplearning/AL-ACDC/data/Cadis/cadis/split2023/data/train/mask\").iterdir())\n",
    "m,p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m, p = count_label(Path(\"/home/yeep/project/py/deeplearning/AL-ACDC/data/Cadis/cadis/split2023/data/val/mask\").iterdir())\n",
    "m,p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = imread(\"/home/yeep/project/py/deeplearning/AL-ACDC/EXP/Cadis/semi/URPC/out_dir/Video8_frame001710.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(i == 7).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "p = np.load(\"/home/yeep/project/py/deeplearning/AL-ACDC/data/Cadis/cadis/split3407/preprocess/test/mask/Video8_frame001710.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(p == 7).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.io import imsave\n",
    "from evalute.metric import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"predicting {str(g)}\")\n",
    "img_npy = reader(g)().read_image(g)\n",
    "mask_npy = reader(g)().read_image(gt)\n",
    "\n",
    "img_npy = functional.normalize(img_npy, mean, std, max_pixel_value=1)\n",
    "img_npy = np.ascontiguousarray(img_npy.transpose(2, 0, 1))[None]\n",
    "\n",
    "img = torch.from_numpy(img_npy).to(device, torch.float32)\n",
    "output, _, _ = model(img)\n",
    "output = torch.stack(output).mean(0)\n",
    "\n",
    "# output = model(img)\n",
    "batch_pred_mask = output.argmax(axis=1)[0]\n",
    "imsave(os.path.join(out_dir,\n",
    "                    str(g.name)[:-4] + \".png\"),\n",
    "        batch_pred_mask.cpu().numpy().astype(np.uint8),\n",
    "        check_contrast=False)\n",
    "\n",
    "class_dice, class_assd = metrics(batch_pred_mask,\n",
    "                                    mask_npy,\n",
    "                                    class_num=8, tolerance=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TSNE_show(X, dims=2, save=False, perplexity=30):\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn import manifold\n",
    "    import numpy as np\n",
    "\n",
    "    tsne = manifold.TSNE(n_components=dims, init='pca', perplexity=perplexity,\n",
    "                         random_state=319).fit_transform(np.array(X))\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.scatter(\n",
    "            tsne[:, 0], tsne[:, 1], 10)\n",
    "    plt.legend(loc='upper left')\n",
    "    if save:\n",
    "        plt.savefig(\"./TSNE_img.svg\", dpi=600, format='svg')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(64,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TSNE_show(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted([442, 458, 403, 140, 233, 706, 565, 300, 1253, 866, 290, 702, 1417, 1587, 1658, 1203, 1528, 589])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted([290, 702, 1658, 1528, 300, 1203, 442, 140, 458, 565, 589, 403, 706, 1587, 1253, 1417, 233, 866])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [list(np.random.randn(100,128)),list(np.random.randn(200,128)),list(np.random.randn(50,128))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.cumsum([len(i)for i in a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = np.concatenate(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.split(c, b[:-1]):\n",
    "    print(i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import one_hot\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot(torch.empty(16,96,96,dtype=torch.long).random_(0,3),3).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dc(pred,label):\n",
    "    pred, label = pred > 0.5, one_hot(label.squeeze(1), pred.shape[1]).permute(0,3,1,2).bool()\n",
    "    tp = torch.sum(pred == label, dim=[-1,-2])\n",
    "    fp = torch.sum(pred == torch.logical_not(label), dim=[-1,-2])\n",
    "    fn = torch.sum(torch.logical_not(pred) == label, dim=[-1,-2])\n",
    "            \n",
    "    nominator = 2 * tp\n",
    "    denominator = 2 * tp + fp + fn\n",
    "    \n",
    "    dc = (nominator + 1e-5) / (torch.clip(denominator + 1e-5, 1e-8))\n",
    "    return dc[:,1:].mean(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = torch.randn(16,3,96,96).softmax(1)\n",
    "label = torch.empty(16,96,96,dtype=torch.long).random_(0,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc(pred,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.vis import build_model,read_yml\n",
    "import torch\n",
    "from os.path import join as osjoin\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset.ACDCDataset import ISICDataset\n",
    "from sklearn.mixture import  GaussianMixture\n",
    "import numpy as np\n",
    "from sklearn.covariance import EmpiricalCovariance\n",
    "from torch import nn\n",
    "from sklearn import manifold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DefeultFeatureExtractor:\n",
    "    def to(self, device):\n",
    "        self.pool.eval()\n",
    "        self.bn.eval()\n",
    "        self.con1x1.eval()\n",
    "\n",
    "        self.pool.to(device)\n",
    "        self.bn.to(device)\n",
    "        self.con1x1.to(device)\n",
    "        return self\n",
    "\n",
    "    def __init__(self, pool_size=12):\n",
    "        self.pool = nn.Sequential(nn.AdaptiveAvgPool2d((pool_size, pool_size)))\n",
    "        self.bn = nn.BatchNorm2d(512)\n",
    "        self.con1x1 = nn.Conv2d(512, 256,\n",
    "                                kernel_size=pool_size, bias=False)\n",
    "\n",
    "    def __call__(self, model_output):\n",
    "        _, _, features = model_output\n",
    "        ret = self.con1x1(self.bn(self.pool(features[0]))).flatten(\n",
    "            1, -1).cpu().numpy()\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MDistance:\n",
    "    def __init__(self) -> None:\n",
    "        self.ec = EmpiricalCovariance(assume_centered=True)\n",
    "\n",
    "    def fit(self, X):\n",
    "        self.ec.fit(X)\n",
    "\n",
    "    def distance(self, x):\n",
    "        return self.ec.mahalanobis(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "COLORS = ['aqua', 'coral', 'midnightblue', 'red', 'darkgreen',\n",
    "          'darkred', 'maroon', 'purple', 'indigo', 'darkslategray', 'black']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpoint = \"/home/yeep/project/py/deeplearning/AL-ACDC/EXP/ISIC/MGUnet_avgalign/checkpoint/c3_best0.8860.pt\"\n",
    "cfg_path  = \"/home/yeep/project/py/deeplearning/AL-ACDC/EXP/ISIC/MGUnet_avgalign/config.yml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = read_yml(cfg_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(cfg)\n",
    "model.load_state_dict(torch.load(ckpoint,map_location=cfg[\"Training\"][\"device\"])[\"model_state_dict\"])\n",
    "model.eval()\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = cfg[\"Dataset\"][\"data_dir\"]\n",
    "dataset = ISICDataset(trainfolder=osjoin(data_dir, \"train\"))\n",
    "loader= DataLoader(dataset, batch_size=16,\n",
    "                    persistent_workers=True, prefetch_factor=4,\n",
    "                    num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = []\n",
    "e = DefeultFeatureExtractor(12).to(cfg[\"Training\"][\"device\"])\n",
    "for img,_ in loader:\n",
    "    embeddings.append(e(model(img.cuda())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.concatenate(embeddings) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = manifold.TSNE(n_components=2, init='pca',\n",
    "                             random_state=319).fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.scatter(tsne[:,0],tsne[:,1],s=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc = MDistance()\n",
    "calc.fit(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance = calc.distance(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm = GaussianMixture(n_components=5,init_params=\"k-means++\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = gmm.fit_predict(distance[:,None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm.predict_proba(distance[:,None]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    idx = np.where(pred==i)\n",
    "    plt.scatter(tsne[idx,0],tsne[idx,1],s=10,c=COLORS[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersect_top_q(a, b, q):\n",
    "    for i in range(q, len(a)):\n",
    "        inter=set(a[:i]) &set(b[:i])\n",
    "        if len(inter) >=q:\n",
    "            return list(inter)[:q]\n",
    "    return a[:q]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(4,8)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "a.sort(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import albumentations as A\n",
    "import numpy as np\n",
    "from matplotlib  import pyplot as plt\n",
    "from skimage.io import imread\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = A.Compose([\n",
    "    \n",
    "        A.Compose([\n",
    "            A.PadIfNeeded(384, 384),\n",
    "            A.ShiftScaleRotate(rotate_limit=90),\n",
    "            A.RandomCrop(194,384)\n",
    "        ],\n",
    "                  p=0.5),\n",
    "        A.RandomGamma(gamma_limit=(0.7, 1.5)),\n",
    "        A.ColorJitter(brightness=32 / 255, saturation=0.2, hue=0.1),\n",
    "        A.Blur(blur_limit=3),\n",
    "        A.OpticalDistortion(),\n",
    "        A.VerticalFlip(),\n",
    "        A.HorizontalFlip(),\n",
    " ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.load(\"/home/yeep/project/py/deeplearning/AL-ACDC/data/Cadis/cadis/split3407/preprocess/train/images/Video1_frame000090.npy\")\n",
    "mask = np.load(\"/home/yeep/project/py/deeplearning/AL-ACDC/data/Cadis/cadis/split3407/preprocess/train/mask/Video1_frame000090.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed = train_transform(image=img,mask=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(transformed[\"image\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = torch.randn(16,256,16,16)\n",
    "mask = torch.randn(16,16,16)>0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y,z = torch.where(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature[x,:,y,z].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def self_cosine_sim(f):\n",
    "    norm_f = F.normalize(f, dim=1)\n",
    "    return torch.matmul(norm_f, norm_f.T).pow(2).mean()\n",
    "def inner_class_var_outer_class_div_feature(model_output):\n",
    "    prediction, _, feature = model_output\n",
    "    if len(prediction)>1:\n",
    "        soft_pred = torch.stack(prediction).mean(0)    \n",
    "    feature = feature[0]\n",
    "\n",
    "    soft_pred = F.adaptive_avg_pool2d(\n",
    "        soft_pred, output_size=feature.shape[2:]).softmax(1)\n",
    "    numclass = soft_pred.shape[1]\n",
    "    mask = soft_pred > 0.5\n",
    "    score = []\n",
    "    for m, f in zip(mask, feature):\n",
    "        class_center = []\n",
    "        inner_class_var = []\n",
    "        for c in range(numclass):\n",
    "            label = m[c]\n",
    "            h, w = torch.where(label)\n",
    "            center = f[:, h, w].mean(1)\n",
    "            class_center.append(center)\n",
    "            inner_class_var.append(self_cosine_sim(f[:, h, w]).item())\n",
    "        inner_class = torch.mean(torch.as_tensor(inner_class_var))\n",
    "        outer_class = self_cosine_sim(torch.stack(class_center))\n",
    "        outer_class = outer_class*0.999+1e-5\n",
    "        score.append(inner_class/outer_class)\n",
    "    return torch.as_tensor(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img,_ in loader:\n",
    "    model_output = model(img.cuda())\n",
    "    score = inner_class_var_outer_class_div_feature(model_output)\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm = GaussianMixture(n_components=30,init_params=\"k-means++\")\n",
    "pred = gmm.fit_predict(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.randint(1, 26, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL.ImageFilter import ModeFilter\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter = ModeFilter(size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = np.random.randint(1,4,size=(16,16),dtype=np.uint8)\n",
    "pred = Image.fromarray(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pred.filter(filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(a)[::4,::4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.bincount(np.array(pred)[::16,::16].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(a)[::16,::16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = range(3,19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.bincount(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mode_filter(image, kernel_size):\n",
    "    '''\n",
    "    image: h w \n",
    "    '''\n",
    "    \n",
    "    if len(kernel_size) == 1:\n",
    "        h = w = kernel_size\n",
    "    elif len(kernel_size) == 2:\n",
    "        w, h = kernel_size\n",
    "        print(kernel_size)\n",
    "    else:\n",
    "        assert \"dim of kernel size is 1 or 2\"\n",
    "    o_h,o_w = image.shape[0]// h,image.shape[1]// w\n",
    "    \n",
    "    if o_h*h > image.shape[0]:\n",
    "        o_h = o_h + 1\n",
    "    \n",
    "    if o_w*w > image.shape[1]:\n",
    "        o_w = o_w + 1\n",
    "        \n",
    "    mode_arr = np.empty(shape=(o_h, o_w),dtype=np.uint8)\n",
    "    i = 0\n",
    "    for hi in range(0, image.shape[0], h):\n",
    "        j = 0\n",
    "        for wi in range(0, image.shape[1], w):\n",
    "            wh,ww = hi + h,wi + w\n",
    "            wh = wh if wh < image.shape[0] else image.shape[0]\n",
    "            ww = ww if ww < image.shape[1] else image.shape[1]\n",
    "            window = image[hi:wh, wi:ww]\n",
    "            c = np.bincount(window.flatten())\n",
    "            mode_arr[i,j] = np.argmax(c)\n",
    "            j+=1\n",
    "        i+=1            \n",
    "    return mode_arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.random.randint(0,3,size=(256,256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.bincount(pred[:16,:16].flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_filter(pred,(16,16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(np.bincount([1,1,2,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.setdefault(1,[]).append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = np.random.randn(1800,1024,256)\n",
    "center = np.random.randn(256,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.matmul(feature,center).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.norm(np.array([[1,1,1],[2,2,2]]),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 不同group之间特征的相似度、关系"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join as osjoin\n",
    "from os.path import exists as osexists\n",
    "from torch.nn.functional import one_hot\n",
    "from os.path import basename\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import ast\n",
    "from albumentations import functional\n",
    "from util import read_yml\n",
    "from model.MGUnet import MGUNet\n",
    "from util.reader import reader\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "from sklearn import manifold\n",
    "import albumentations as A\n",
    "from util import SubsetSampler\n",
    "from pathlib import Path\n",
    "from util import get_dataloader_ISIC\n",
    "from dataset.ACDCDataset import ISICDataset\n",
    "from util import jitfunc as f\n",
    "from torch.nn import functional as F\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dc(pred, label):\n",
    "    pred, label = pred > 0.5, one_hot(label.squeeze(\n",
    "        1), pred.shape[1]).permute(0, 3, 1, 2).bool()\n",
    "    tp = torch.sum(pred == label, dim=[-1, -2])\n",
    "    fp = torch.sum(pred == torch.logical_not(label), dim=[-1, -2])\n",
    "    fn = torch.sum(torch.logical_not(pred) == label, dim=[-1, -2])\n",
    "\n",
    "    nominator = 2 * tp\n",
    "    denominator = 2 * tp + fp + fn\n",
    "\n",
    "    dc = (nominator + 1e-5) / (torch.clip(denominator + 1e-5, 1e-8))\n",
    "    return dc[:, 1:].mean(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _dif( a):\n",
    "    r = [a[0], ]\n",
    "    for i in range(1, len(a)):\n",
    "        if len(a[i]) > len(a[i-1]):\n",
    "            r.append(a[i] - a[i-1])\n",
    "        else:\n",
    "            r.append(a[i-1] - a[i])\n",
    "    return r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_query_record(filepath):\n",
    "    if not osexists(filepath):\n",
    "        raise FileNotFoundError\n",
    "\n",
    "    with open(filepath) as fp:\n",
    "        indices = fp.readlines()\n",
    "    lab, unlab = indices[::2], indices[1::2]\n",
    "\n",
    "    lab, unlab = [set(ast.literal_eval(l.strip())) for l in lab], \\\n",
    "        [set(ast.literal_eval(l.strip())) for l in unlab]\n",
    "    # print(unlab)\n",
    "    lab, unlab = _dif(lab), _dif(unlab)\n",
    "\n",
    "    return lab[0], lab[1:], unlab[0], unlab[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(cfg):\n",
    "    device = cfg[\"Training\"][\"device\"]\n",
    "    model = MGUNet(cfg[\"Network\"]).to(device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class IDataset(Dataset):\n",
    "    def __init__(self, trainfolder, transform=None) -> None:\n",
    "        super().__init__()\n",
    "        self.folder = trainfolder\n",
    "        self.images = list((Path(trainfolder) / \"images\").glob(\"*.npy\"))\n",
    "        self.transforms = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        data = np.load(str(self.images[index]))\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            transformed = self.transforms(image=data)\n",
    "            data = transformed[\"image\"]\n",
    "\n",
    "        return torch.tensor(np.transpose(data, [2, 0, 1]))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def embedding(model, loader, feature_extractor):\n",
    "    model.eval()\n",
    "    device = next(iter(model.parameters())).device\n",
    "\n",
    "    features = []\n",
    "    for img in loader:\n",
    "        img = img.to(device, torch.float32)\n",
    "        model_output = model(img)\n",
    "        features += list(feature_extractor(model_output))\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dir = \"/home/yeep/project/py/deeplearning/AL-ACDC/EXP/MGCNet/MGUnetVar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = training_dir\n",
    "query_file = osjoin(base_dir, 'query_state')\n",
    "init_labeled, labeled, init_unlabeled, unlabeled = _get_query_record(\n",
    "    query_file)\n",
    "ckdir = osjoin(base_dir, 'checkpoint')\n",
    "ckpoints = sorted([osjoin(ckdir, i) for i in os.listdir(\n",
    "    ckdir) if \"best\" in i], key=lambda x: int(basename(x).split('_')[0][1:]))\n",
    "cycle_num = len(ckpoints)\n",
    "cfg = read_yml(osjoin(base_dir, \"config.yml\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_loader(idxs, with_label=False):\n",
    "    sampler = SubsetSampler(list(idxs))\n",
    "    data_dir = cfg[\"Dataset\"][\"data_dir\"]\n",
    "    if not with_label:\n",
    "        dataset = IDataset(trainfolder=osjoin(data_dir, \"train\"))\n",
    "    elif with_label:\n",
    "        dataset = ISICDataset(trainfolder=osjoin(data_dir, \"train\"))\n",
    "    return DataLoader(dataset, batch_size=16,\n",
    "                        sampler=sampler, persistent_workers=True, prefetch_factor=4,\n",
    "                        num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(loaders,feature_order=0):\n",
    "    group_prediction = [[],[],[],[]]\n",
    "    sim = []\n",
    "    rdsim = []\n",
    "    model.eval()\n",
    "    for img,mask in loaders:\n",
    "        img,mask = img.to(cfg[\"Training\"][\"device\"]),mask.to(cfg[\"Training\"][\"device\"])\n",
    "        prediction,_,feature= model(img)\n",
    "        \n",
    "        for i,p in enumerate(prediction):\n",
    "            group_prediction[i] += dc(p,mask).cpu().numpy().tolist()\n",
    "                \n",
    "        f = feature[feature_order]\n",
    "        group_features = torch.split(f,int(f.shape[1]/4),dim=1)\n",
    "        shapesim = []\n",
    "        randsim = []\n",
    "        for i in range(len(group_features)):\n",
    "            for j in range(len(group_features)):\n",
    "                f1 = group_features[i].permute(0,2,3,1)\n",
    "                f2 = group_features[j].permute(0,2,3,1)\n",
    "                hwsim = F.cosine_similarity(f1,f2,dim=3)\n",
    "                s = hwsim.mean(dim=(-1,-2))\n",
    "                tmp = []\n",
    "                for _ in range(6):\n",
    "                    x,y = torch.randint(0,f1.shape[1],size=(2,))\n",
    "                    tmp.append(hwsim[...,x,y])\n",
    "                randsim.append(torch.stack(tmp).mean(0))\n",
    "                shapesim.append(s)\n",
    "        sim.append(shapesim) \n",
    "        rdsim.append(randsim) \n",
    "        \n",
    "    sample_sim = torch.concat([torch.stack(s).transpose(1,0) for s in sim]) \n",
    "    rdsim = torch.concat([torch.stack(s).transpose(1,0) for s in rdsim]) \n",
    "    group_prediction = torch.stack([torch.as_tensor(p) for p in group_prediction])\n",
    "    return sample_sim,rdsim,group_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7f9ffb966700>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_grad_enabled( False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unlabeled_idx ,labeled_idx= init_unlabeled,init_labeled\n",
    "model = build_model(cfg)\n",
    "model.load_state_dict(torch.load(ckpoints[0], map_location=cfg[\"Training\"][\"device\"])[\"model_state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cylce_unsample_sim,cycle_unrdsim,cycle_ungroup_prediction = [],[],[]\n",
    "cylce_sample_sim,cycle_rdsim,cycle_group_prediction = [],[],[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in range(cycle_num):\n",
    "    unloaders = build_loader(unlabeled_idx,with_label=True)    \n",
    "    loaders = build_loader(labeled_idx,with_label=True)    \n",
    "    unsample_sim,unrdsim,ungroup_prediction = inference(unloaders)\n",
    "    labsample_sim,labrdsim,labgroup_prediction = inference(loaders)\n",
    "    \n",
    "    cylce_unsample_sim.append(unsample_sim.cpu().numpy())\n",
    "    cycle_unrdsim.append(unrdsim.cpu().numpy())\n",
    "    cycle_ungroup_prediction.append(ungroup_prediction.cpu().numpy())\n",
    "    \n",
    "    cylce_sample_sim.append(labsample_sim.cpu().numpy())\n",
    "    cycle_rdsim.append(labrdsim.cpu().numpy())\n",
    "    cycle_group_prediction.append(labgroup_prediction.cpu().numpy())\n",
    "    if c == 3:\n",
    "        break\n",
    "    unlabeled_idx = unlabeled_idx -  unlabeled[c]\n",
    "    labeled_idx = labeled_idx | labeled[c]\n",
    "    model.load_state_dict(torch.load(ckpoints[c+1], map_location=cfg[\"Training\"][\"device\"])[\"model_state_dict\"])\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.triu(np.ones(4),0) - np.eye(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 1, 3])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(cylce_unsample_sim[3].mean(0).reshape(4,4)*(1-np.eye(4))).mean(1).argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3, 2, 0])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cycle_ungroup_prediction[3].mean(1).argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.91549116, 0.9446809, 0.9564784, 0.96298516]\n",
      "[0.9969658, 0.9899896, 0.993434, 0.9905345]\n"
     ]
    }
   ],
   "source": [
    "print([a.mean()for a in cycle_ungroup_prediction])\n",
    "print([a.mean()for a in cycle_group_prediction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_mean = [i.mean(0) for i in cylce_unsample_sim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[[(sample_mean[j].reshape(4,4)*(1-np.eye(4))[i]).mean() for i in range(4)] for j in range(4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([(s.reshape(-1,4,4)*mask).std() for s in cylce_unsample_sim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(s.reshape(-1,4,4)*mask).std() for s in cylce_unsample_sim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([(s.reshape(-1,4,4)*mask).std() for s in cycle_unrdsim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(s.reshape(-1,4,4)*mask).std() for s in cycle_unrdsim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([(s.reshape(-1,4,4)*mask).std() for s in cylce_sample_sim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(s.reshape(-1,4,4)*mask).mean() for s in cycle_unrdsim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([(s.reshape(-1,4,4)*mask).std() for s in cycle_rdsim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ungroup_prediction.mean(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.randn(16,256,18,18).transpose(0,2,3,1)\n",
    "b = (np.random.randn(16,18,18) > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1508, 256)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[b,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = []*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43ml\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "l[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = torch.randn(16,32,32,256,1)\n",
    "c = torch.randn(256,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 32, 32, 4])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.cosine_similarity(f,c,dim=-2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 32, 32, 256, 1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 32, 32, 256, 1, 1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f[...,None].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.randint(0,3,size=(16,4,32,32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 4, 32, 32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "o = torch.randint(0, 4,size=(16,4,32,32),dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = F.interpolate(o,size=(16,16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 2., 3.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.unique(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nnunetv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
